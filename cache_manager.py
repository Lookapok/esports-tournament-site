#!/usr/bin/env python3
"""
å¿«å–ç®¡ç†å’Œè¨ºæ–·å·¥å…·
ç”¨æ–¼æ¸¬è©¦å¿«å–é…ç½®ã€æ¸…é™¤å¿«å–ã€ç›£æ§å¿«å–æ•ˆæœ
"""

import os
import django
import sys

# è¨­å®š Django ç’°å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'esports_site.settings')
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

django.setup()

from django.core.cache import cache
from django.conf import settings
import time
import json
from datetime import datetime

class CacheManager:
    def __init__(self):
        self.cache_backend = settings.CACHES['default']['BACKEND']
        self.cache_version = getattr(settings, 'CACHE_VERSION', 1)
        
    def diagnose_cache_config(self):
        """è¨ºæ–·å¿«å–é…ç½®"""
        print("ğŸ” å¿«å–é…ç½®è¨ºæ–·")
        print("=" * 50)
        
        print(f"å¿«å–å¾Œç«¯: {self.cache_backend}")
        print(f"å¿«å–ç‰ˆæœ¬: {self.cache_version}")
        
        if 'redis' in self.cache_backend.lower():
            print("âœ… ä½¿ç”¨ Redis å¿«å–")
            try:
                location = settings.CACHES['default'].get('LOCATION', 'N/A')
                print(f"Redis ä½ç½®: {location}")
                timeout = settings.CACHES['default'].get('TIMEOUT', 'N/A')
                print(f"é è¨­è¶…æ™‚: {timeout} ç§’")
            except Exception as e:
                print(f"âš ï¸  Redis è¨­å®šæª¢æŸ¥å¤±æ•—: {e}")
        else:
            print("ğŸ’» ä½¿ç”¨æœ¬åœ°è¨˜æ†¶é«”å¿«å–")
            try:
                location = settings.CACHES['default'].get('LOCATION', 'N/A')
                print(f"å¿«å–ä½ç½®: {location}")
                max_entries = settings.CACHES['default'].get('OPTIONS', {}).get('MAX_ENTRIES', 'N/A')
                print(f"æœ€å¤§æ¢ç›®: {max_entries}")
            except Exception as e:
                print(f"âš ï¸  æœ¬åœ°å¿«å–è¨­å®šæª¢æŸ¥å¤±æ•—: {e}")
                
    def test_cache_functionality(self):
        """æ¸¬è©¦å¿«å–åŸºæœ¬åŠŸèƒ½"""
        print("\nğŸ§ª å¿«å–åŠŸèƒ½æ¸¬è©¦")
        print("=" * 50)
        
        test_cases = [
            ('simple_string', 'Hello Cache!', 60),
            ('complex_dict', {'name': 'test', 'data': [1, 2, 3]}, 60),
            ('large_data', 'x' * 10000, 60),  # 10KB æ¸¬è©¦æ•¸æ“š
        ]
        
        results = []
        
        for key, value, timeout in test_cases:
            test_key = f'cache_test_{key}_v{self.cache_version}'
            
            # æ¸¬è©¦å¯«å…¥
            try:
                write_start = time.time()
                cache.set(test_key, value, timeout)
                write_time = time.time() - write_start
                
                # æ¸¬è©¦è®€å–
                read_start = time.time()
                cached_value = cache.get(test_key)
                read_time = time.time() - read_start
                
                # é©—è­‰æ•¸æ“šæ­£ç¢ºæ€§
                if cached_value == value:
                    status = "âœ… æˆåŠŸ"
                    print(f"{key}: {status} (å¯«å…¥: {write_time:.3f}s, è®€å–: {read_time:.3f}s)")
                else:
                    status = "âŒ æ•¸æ“šä¸åŒ¹é…"
                    print(f"{key}: {status}")
                    
                results.append({
                    'key': key,
                    'status': status,
                    'write_time': write_time,
                    'read_time': read_time,
                    'data_size': len(str(value))
                })
                
                # æ¸…ç†æ¸¬è©¦æ•¸æ“š
                cache.delete(test_key)
                
            except Exception as e:
                status = f"âŒ éŒ¯èª¤: {e}"
                print(f"{key}: {status}")
                results.append({
                    'key': key,
                    'status': status,
                    'error': str(e)
                })
                
        return results
        
    def test_cache_keys(self):
        """æ¸¬è©¦æ‡‰ç”¨ç¨‹å¼å¿«å–éµ"""
        print("\nğŸ”‘ æ‡‰ç”¨ç¨‹å¼å¿«å–éµæ¸¬è©¦")
        print("=" * 50)
        
        app_cache_keys = [
            f'tournament_list_v{self.cache_version}',
            f'tournament_detail_v{self.cache_version}_9_page_1',
            f'team_list_v{self.cache_version}_page_1',
        ]
        
        for cache_key in app_cache_keys:
            try:
                cached_value = cache.get(cache_key)
                if cached_value is not None:
                    print(f"âœ… {cache_key}: å·²å¿«å–")
                else:
                    print(f"âšª {cache_key}: æœªå¿«å–")
            except Exception as e:
                print(f"âŒ {cache_key}: éŒ¯èª¤ - {e}")
                
    def clear_all_cache(self):
        """æ¸…é™¤æ‰€æœ‰å¿«å–"""
        print("\nğŸ—‘ï¸ æ¸…é™¤å¿«å–")
        print("=" * 50)
        
        try:
            cache.clear()
            print("âœ… æ‰€æœ‰å¿«å–å·²æ¸…é™¤")
        except Exception as e:
            print(f"âŒ å¿«å–æ¸…é™¤å¤±æ•—: {e}")
            
    def benchmark_cache_performance(self):
        """å¿«å–æ€§èƒ½åŸºæº–æ¸¬è©¦"""
        print("\nâš¡ å¿«å–æ€§èƒ½åŸºæº–æ¸¬è©¦")
        print("=" * 50)
        
        test_data = {
            'small': 'x' * 100,      # 100 bytes
            'medium': 'x' * 10000,   # 10 KB
            'large': 'x' * 100000,   # 100 KB
        }
        
        results = {}
        
        for size_name, data in test_data.items():
            print(f"\nğŸ“Š æ¸¬è©¦ {size_name} æ•¸æ“š ({len(data)} bytes):")
            
            # å¤šæ¬¡æ¸¬è©¦å–å¹³å‡å€¼
            write_times = []
            read_times = []
            
            for i in range(5):
                test_key = f'benchmark_{size_name}_{i}_v{self.cache_version}'
                
                # å¯«å…¥æ¸¬è©¦
                write_start = time.time()
                cache.set(test_key, data, 300)
                write_time = time.time() - write_start
                write_times.append(write_time)
                
                # è®€å–æ¸¬è©¦
                read_start = time.time()
                cached_data = cache.get(test_key)
                read_time = time.time() - read_start
                read_times.append(read_time)
                
                # æ¸…ç†
                cache.delete(test_key)
                
            avg_write = sum(write_times) / len(write_times)
            avg_read = sum(read_times) / len(read_times)
            
            print(f"   å¹³å‡å¯«å…¥æ™‚é–“: {avg_write:.4f}s")
            print(f"   å¹³å‡è®€å–æ™‚é–“: {avg_read:.4f}s")
            print(f"   å¯«å…¥é€Ÿåº¦: {len(data) / avg_write / 1024:.1f} KB/s")
            print(f"   è®€å–é€Ÿåº¦: {len(data) / avg_read / 1024:.1f} KB/s")
            
            results[size_name] = {
                'data_size': len(data),
                'avg_write_time': avg_write,
                'avg_read_time': avg_read,
                'write_speed_kbps': len(data) / avg_write / 1024,
                'read_speed_kbps': len(data) / avg_read / 1024
            }
            
        return results
        
    def generate_cache_report(self):
        """ç”Ÿæˆå¿«å–è¨ºæ–·å ±å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆå¿«å–è¨ºæ–·å ±å‘Š")
        print("=" * 70)
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'cache_backend': self.cache_backend,
            'cache_version': self.cache_version,
            'config_info': {
                'backend': self.cache_backend,
                'timeout': settings.CACHES['default'].get('TIMEOUT', 'N/A'),
                'location': settings.CACHES['default'].get('LOCATION', 'N/A'),
            }
        }
        
        # åŸ·è¡Œå„é …æ¸¬è©¦
        print("åŸ·è¡ŒåŠŸèƒ½æ¸¬è©¦...")
        report['functionality_tests'] = self.test_cache_functionality()
        
        print("åŸ·è¡Œæ€§èƒ½æ¸¬è©¦...")
        report['performance_tests'] = self.benchmark_cache_performance()
        
        # ä¿å­˜å ±å‘Š
        with open('cache_diagnostic_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
            
        print(f"\nâœ… å¿«å–è¨ºæ–·å ±å‘Šå·²ä¿å­˜åˆ°: cache_diagnostic_report.json")
        
        # å¿«å–ç‹€æ…‹ç¸½çµ
        self.print_cache_summary(report)
        
    def print_cache_summary(self, report):
        """æ‰“å°å¿«å–ç‹€æ…‹ç¸½çµ"""
        print("\nğŸ“ˆ å¿«å–ç‹€æ…‹ç¸½çµ")
        print("=" * 50)
        
        # åŠŸèƒ½æ¸¬è©¦çµæœ
        func_tests = report.get('functionality_tests', [])
        successful_tests = sum(1 for test in func_tests if 'âœ…' in test.get('status', ''))
        total_tests = len(func_tests)
        
        print(f"åŠŸèƒ½æ¸¬è©¦: {successful_tests}/{total_tests} é€šé")
        
        # æ€§èƒ½æ¸¬è©¦çµæœ
        perf_tests = report.get('performance_tests', {})
        if perf_tests:
            avg_read_speed = sum(test['read_speed_kbps'] for test in perf_tests.values()) / len(perf_tests)
            avg_write_speed = sum(test['write_speed_kbps'] for test in perf_tests.values()) / len(perf_tests)
            
            print(f"å¹³å‡è®€å–é€Ÿåº¦: {avg_read_speed:.1f} KB/s")
            print(f"å¹³å‡å¯«å…¥é€Ÿåº¦: {avg_write_speed:.1f} KB/s")
            
        # å»ºè­°
        print("\nğŸ’¡ å»ºè­°:")
        if 'locmem' in self.cache_backend.lower():
            print("1. è€ƒæ…®å‡ç´šåˆ° Redis å¿«å–ä»¥ç²å¾—æ›´å¥½çš„æ€§èƒ½")
        
        if successful_tests < total_tests:
            print("2. æª¢æŸ¥å¿«å–é…ç½®ï¼Œéƒ¨åˆ†åŠŸèƒ½æ¸¬è©¦å¤±æ•—")
            
        print("3. å®šæœŸæ¸…é™¤å¿«å–ä»¥ç¢ºä¿æ•¸æ“šæ–°é®®åº¦")
        print("4. ç›£æ§å¿«å–å‘½ä¸­ç‡ä»¥å„ªåŒ–å¿«å–ç­–ç•¥")

if __name__ == "__main__":
    manager = CacheManager()
    
    print("ğŸš€ é–‹å§‹å¿«å–è¨ºæ–·...")
    
    manager.diagnose_cache_config()
    manager.test_cache_keys()
    manager.generate_cache_report()
    
    print("\nğŸ¯ å¿«å–è¨ºæ–·å®Œæˆï¼")
    print("å¦‚éœ€æ¸…é™¤å¿«å–ï¼Œè«‹åŸ·è¡Œ: python cache_manager.py --clear")
